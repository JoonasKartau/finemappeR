% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/FINEMAP.R
\name{original_finemap}
\alias{original_finemap}
\title{Fine-mapping GWASS summary stastics}
\usage{
original_finemap(
  betas,
  ses,
  R,
  tau = 0.05,
  n_reps = 50,
  prob_threshold = 0.001,
  max_causals = 5,
  cred_sizes = NULL,
  meta_analyze = T,
  quiet = T,
  RM = NULL,
  estimate_M = FALSE,
  n_studies,
  variant_sample_sizes = NULL,
  max_overlap = T,
  freqs,
  scaled_data = F,
  use_N = F,
  INFO = NULL,
  cholesky = T,
  rsid = NULL,
  position = NULL,
  allele1 = NULL,
  allele2 = NULL,
  chromosome = NULL,
  export_configs = FALSE,
  init_config = NULL
)
}
\arguments{
\item{betas}{A vector or matrix of GWAS marginal effects.
Takes the form of a vector if there is only a single dataset or the data has
been combined in advance. Otherwise, it is a matrix where each column contains
the marginal effects for one dataset. For any unobserved variants in a study,
the marginal effects should be set to \code{0}.}

\item{ses}{A vector or matrix of GWAS marginal effect standard errors.
Takes the form of a vector if there is only a single dataset or the data has
been combined in advance. Otherwise, it is a matrix where each column contains
the standard errors for one dataset. For any unobserved variants in a study,
the standard errors should be set to \code{Inf}.}

\item{R}{Reference LD matrix for the set of analyzed variants.}

\item{tau}{Prior standard error for the casual effects. Set by default to \code{0.05}.}

\item{n_reps}{Maximum number of Stochastic Shotgun Search (SSS) iterations.}

\item{prob_threshold}{SSS termination threshold, based on probability mass added at each iteration.}

\item{max_causals}{Maximum number of causal variants.}

\item{cred_sizes}{Vector or numeric of size of credible sets to be evaluated. If no value
is provided, the rounded expected posterior for number of causal variants is used.}

\item{meta_analyze}{Binary variable, should the data be meta-analyzed? If data has been
combined in advance, should be set to \code{FALSE}.}

\item{quiet}{Should the current progress of SSS be repressed?}

\item{RM}{If \eqn{\boldsymbol{R_M}} has been computed in advance, it can be provided as input.}

\item{estimate_M}{Should \eqn{\boldsymbol{M}} be estimated? This should be used if data has been meta-analyzed in advance.}

\item{n_studies}{Number of studies. Should be equal to the number of columns in
ses abnd betas. If the data has been combined in advance, set to \code{1}.}

\item{variant_sample_sizes}{Vector of combined sample sizes per variant, from the meta-analysis.}

\item{max_overlap}{Binary parameter denoting whether the maximum sample
overlap is assumed when estimating \eqn{\boldsymbol{M}}.}

\item{freqs}{A vector or matrix of variant frequencies.
Takes the form of a vector if there is only a single dataset or the data has
been combined in advance. Otherwise, it is a matrix where each column contains
the variant frequencies for one dataset. For any unobserved variants in a study,
the marginal effects should be set to \code{0}.}

\item{scaled_data}{Has the data been scaled with allele frequencies in advance?}

\item{use_N}{Are the variant sample sizes or marginal effect standard errors used
for fine-mapping?}

\item{INFO}{Vector of variant imputation INFO scores.}

\item{cholesky}{Is cholesky decomposition used for matrix inversion? If not base R \code{solve} is used.}

\item{rsid}{rsid vector (optional identifier).}

\item{position}{position vector (optional identifier).}

\item{allele1}{reference allele vector (optional identifier).}

\item{allele2}{alternate allele vector (optional identifier).}

\item{chromosome}{chromosome vector (optional identifier).}

\item{init_config}{Initial configuration, from which fine-mapping is started.}

\item{cred_eval}{Binary variable, should credible sets be computed?}
}
\value{
A list of objects
\describe{
  \item{\code{summary_table}}{Data frame with entries:
  \itemize{
  \item{\code{rank}: The order in which the variants appear when sorted by PIP.}
  \item{\code{rsid}: Rsid (if supplied, NA otherwise).}
  \item{\code{chromosome}: Chromosome (if supplied, NA otherwise).}
  \item{\code{allele1}: Allele1 (if supplied, NA otherwise).}
  \item{\code{allele2}: Allele2 (if supplied, NA otherwise).}
  \item{\code{maf}: Minor allele frequency.}
  \item{\code{beta}: Marginal effect.}
  \item{\code{se}: Standard error.}
  \item{\code{z}: Z-score.}
  \item{\code{prob}: Posterior inclusion probability (PIP).}
  }}
  \item{\code{cred}}{List or matrix of credible sets.}
  \item{\code{post_k}}{Posterior probability distribution for the number of causal variants from \code{0:max_causals}}
  \item{\code{evaluated_configs}}{Optional output if \code{export_configs == TRUE}. Data frame of evaluated configurations and associated information.
  \itemize{
   \item{\code{configuration}: Causal configuration.}
   \item{\code{log_bf}: Causal configuration log Bayes-factor.}
   \item{\code{config_size}: Causal configuration size (how many causal variants?).}
   \item{\code{unique_config}: Is this a unique configuration?.}
  }}
 }
}
\description{
\code{original_finemap} performs Bayesian variable selection on a set of genetic
variants and a phenotype, using marginal effect estimates \eqn{\boldsymbol{\widehat \beta}},
 their standard errors \eqn{\boldsymbol{s}}, and  a reference LD panel \eqn{\boldsymbol{R}}
 as input. This is a recreation of the C++ implementation by Christian Benner and Matti Pirinen.
 Not recommended for meta-analyzed GWAS data.
}
\examples{
#Running FINEMAP with imputed summary statistics

#Loading toy data with one true causal variant.
data("toydata_finemapmiss")

betas <- toydata_finemapmiss$betas
ses <- toydata_finemapmiss$ses
MAF <- toydata_finemapmiss$MAF
LD <- toydata_finemapmiss$LD

n <- toydata_finemapmiss$study_sample_sizes
p <- dim(LD)[1]

#Simulating missingness in 20\% of variants (including the true causal variant)
missing_data <- unique(sort(c(toydata_finemapmiss$causal_snp,
                              cbind(sample(1:p, round(p*0.2))))))

#Which dataset are the variants missing from?
which_dataset_missing <- sample(1:2, length(missing_data), replace = TRUE)

#Setting missing data to 0 or Inf.
betas[missing_data[which_dataset_missing == 1],1] <- 0
betas[missing_data[which_dataset_missing == 2],2] <- 0
ses[missing_data[which_dataset_missing == 1],1] <- Inf
ses[missing_data[which_dataset_missing == 2],2] <- Inf
MAF[missing_data[which_dataset_missing == 1],1] <- 0
MAF[missing_data[which_dataset_missing == 2],2] <- 0

#Setting variants sample sizes
variant_sample_sizes <- rep(sum(n), p)
variant_sample_sizes[missing_data] <- n[1]

#Index of observed variants from each study
obs1 <- setdiff(1:p, missing_data[which_dataset_missing == 1])
obs2 <- setdiff(1:p, missing_data[which_dataset_missing == 2])

#'#Index of unobserved variants from each study
unobs1 <- sort(missing_data[which_dataset_missing == 1])
unobs2 <- sort(missing_data[which_dataset_missing == 2])

#z-scores from each study
z_obs1 <- (betas/ses)[obs1, 1]
z_obs2 <- (betas/ses)[obs2, 2]

imputation1 <- impute_summary_stats(R = LD, z = z_obs1,
                                    observed = obs1,
                                    unobserved = unobs1, n = n[1],
                                    return_z = FALSE, scale = TRUE)


imputation2 <- impute_summary_stats(R = LD, z = z_obs2,
                                   observed = obs2,
                                   unobserved = unobs2, n = n[2],
                                   return_z = FALSE, scale = TRUE)

#Copying over summary statistics
betas_imputed <- betas
ses_imputed <- ses

#Using imputed values to replace missing observations
betas_imputed[unobs1,1] <- imputation1[,1]
ses_imputed[unobs1,1] <- imputation1[,3]

betas_imputed[unobs2,2] <- imputation2[,1]
ses_imputed[unobs2,2] <- imputation2[,3]

#Assuming all variants fully observed after imputation
variant_sample_sizes <- rep(sum(n),p)

#Running FINEMAP
output_FM <- original_finemap(ses = ses,
                         betas = betas,
                         R = LD,
                         n_studies = 2,
                         variant_sample_sizes = variant_sample_sizes,
                         freqs = MAF)





}
